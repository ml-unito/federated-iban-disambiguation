{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['BIC', 'AccountNumber', 'CTRYbnk', 'Name', 'IsShared', 'Holder'], dtype='object')\n",
      "657\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"./dataset_100_IBAN_prova.csv\",index_col=0)\n",
    "dataset = dataset.drop(\"Address\",axis=1)\n",
    "print(dataset.columns)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance\n",
    "from itertools import combinations\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "#nltk.download('punkt')\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def remove_punctuation(string):\n",
    "    \"\"\" \"\"\"\n",
    "    return \" \".join(tokenizer.tokenize(string))\n",
    "\n",
    "def preprocess_text(string):\n",
    "    \"\"\" \"\"\"\n",
    "    removed = remove_punctuation(string)\n",
    "    return removed.upper().strip()\n",
    "\n",
    "\n",
    "for i in range(len(dataset)):    \n",
    "    if isinstance(dataset.loc[i, \"Name\"],str):\n",
    "        dataset.loc[i, \"Name\"] = preprocess_text(dataset.loc[i, \"Name\"])\n",
    "    \n",
    "dataset = dataset.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIC                           HMHGETBZ\n",
      "AccountNumber       NL71BNUZ6616215301\n",
      "CTRYbnk                             ET\n",
      "Name                WULFF GMBH CO KGAA\n",
      "IsShared                             1\n",
      "Holder           Wulff GmbH & Co. KGaA\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "len(dataset)\n",
    "print(dataset.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Seip Rohleder e.G.', 3), ('Karz Henschel AG', 2), ('Gunpf', 1), ('Mälzer KG', 0)]\n",
      "0 ['Mälzer KG']\n",
      "1 ['Gunpf']\n",
      "2 ['Karz Henschel AG']\n",
      "3 ['Seip Rohleder e.G.']\n"
     ]
    }
   ],
   "source": [
    "import jaro\n",
    "import numpy as np\n",
    "from Levenshtein import ratio\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "\n",
    "def computeAvgDistanceInNames(group, iban, d):\n",
    "    \"\"\" \"\"\"\n",
    "    couples = list(combinations(group[\"Name\"], 2))\n",
    "    distances = []\n",
    "    \n",
    "    if d == \"edit\":\n",
    "        for couple in couples:distances.append(ratio(couple[0], couple[1]))\n",
    "    elif d == \"jaro\":\n",
    "        for couple in couples:distances.append(jaro.jaro_winkler_metric(couple[0], couple[1]))\n",
    "    elif d == \"hamming\":\n",
    "        for couple in couples:distances.append(distance.hamming(list(couple[0]), list(couple[1])))\n",
    "    else:\n",
    "        raise Exception(\"Distance not supported\")\n",
    "    \n",
    "    return sum(distances) / len(distances)\n",
    "\n",
    "\n",
    "def computeMedoidsAsName(result_set, iban, names, d, clusters=None):\n",
    "    \"\"\" \"\"\"\n",
    "    if len(names) == 1:\n",
    "        result_set[iban]['Names'].append(names[0])\n",
    "        return result_set\n",
    "    \n",
    "    distances = []\n",
    "    best = np.inf\n",
    "    best_name = \"\"\n",
    "    for name1 in names:\n",
    "        for name2 in [el for el in names if el != name1]:\n",
    "            if d == \"edit\":\n",
    "                distances.append(ratio(name1, name2))\n",
    "            elif d == \"jaro\":\n",
    "                distances.append(jaro.jaro_winkler_metric(name1, name2))\n",
    "            elif d == \"hamming\":\n",
    "                distances.append(distance.hamming(list(name1), list(name2)))\n",
    "            else:\n",
    "                raise Exception(\"Distance not supported\")\n",
    "        \n",
    "        actual = sum(distances) / (len(names) - 1)\n",
    "        if best > actual:\n",
    "            best = actual\n",
    "            best_name = name1\n",
    "    \n",
    "    #print(\"PRIMA\")\n",
    "    #print(result_set)\n",
    "    result_set[iban]['Names'].append(best_name)\n",
    "    #print(\"DOPO\")\n",
    "    #print(result_set)\n",
    "    return result_set\n",
    "\n",
    "\n",
    "\n",
    "def AgglomerativeC(iban, names, d, cluster_threshold):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    # Compute the pairwise distance matrix\n",
    "    n = len(names)\n",
    "    distance_matrix = np.zeros((n, n))\n",
    "\n",
    "    if d == \"edit\":\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                dist = ratio(names[i], names[j])\n",
    "                distance_matrix[i, j] = 1 -dist\n",
    "                distance_matrix[j, i] = 1 -dist\n",
    "                #print(names[i], names[j], 1-dist)\n",
    "                \n",
    "\n",
    "    # Perform agglomerative clustering\n",
    "    clustering = AgglomerativeClustering( n_clusters=None, metric='precomputed', linkage='average', distance_threshold=cluster_threshold)\n",
    "    clusters = clustering.fit_predict(distance_matrix)\n",
    "    # Print the resulting clusters\n",
    "    #for idx, cluster in enumerate(clusters):\n",
    "    #    print(f\"String: {names[idx]}, Cluster: {cluster}\")    \n",
    "    \n",
    "    return clusters\n",
    "\n",
    "# nomi = ['Seip Rohleder e.G.', 'Karz Henschel AG', 'Gunpf', 'Mälzer KG']\n",
    "# clusters = AgglomerativeC(\"\", nomi , \"edit\", 0.4)\n",
    "\n",
    "# res = list(enumerate(clusters))\n",
    "# res = [(nomi[el[0]], el[1]) for el in res]\n",
    "# print(res)\n",
    "# clusters = list(set(clusters))\n",
    "\n",
    "# for c in clusters:\n",
    "#     n = [el[0] for el in res if el[1] == c]\n",
    "#     print(c, n)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.0\n"
     ]
    }
   ],
   "source": [
    "result_set = {\n",
    "}\n",
    "\n",
    "d = \"edit\"\n",
    "threshold = 0.1\n",
    "cluster_threshold = 0.7\n",
    "\n",
    "groupped = dataset.groupby(\"AccountNumber\")\n",
    "for iban, group in groupped:\n",
    "    \n",
    "    if len(group) == 1:\n",
    "        result_set[iban] = {\n",
    "            \"Real_IsShared\": group.iloc[0][\"IsShared\"],\n",
    "            \"Holders\": list(set(group[\"Holder\"])),\n",
    "            \"IsShared\": 0,\n",
    "            \"Names\": group[\"Name\"].tolist()\n",
    "        }\n",
    "        \n",
    "    else:\n",
    "        avg_distance_acc = computeAvgDistanceInNames(group, iban, d)\n",
    "        #print(avg_distance_acc)\n",
    "        \n",
    "        if avg_distance_acc <= threshold:\n",
    "            result_set[iban] = {\n",
    "                \"Real_IsShared\": group.iloc[0][\"IsShared\"],\n",
    "                \"Holders\": list(set(group[\"Holder\"])),\n",
    "                \"IsShared\": 0,\n",
    "                \"Names\": []\n",
    "            }\n",
    "            result_set = computeMedoidsAsName(result_set, iban, group['Name'].tolist(), d)\n",
    "        else:\n",
    "            result_set[iban] = {\n",
    "                \"Real_IsShared\": group.iloc[0][\"IsShared\"],\n",
    "                \"Holders\": list(set(group[\"Holder\"])),\n",
    "                \"IsShared\": 1,\n",
    "                \"Names\": []\n",
    "            }\n",
    "            name_list = group[\"Name\"].tolist()\n",
    "            clusters = AgglomerativeC(iban, name_list, d, cluster_threshold)\n",
    "            res = list(enumerate(clusters))\n",
    "            res = [(name_list[el[0]], el[1]) for el in res]\n",
    "            clusters = list(set(clusters))\n",
    "            \n",
    "            \n",
    "            #print(clusters)\n",
    "            for c in clusters:\n",
    "                nomi = [el[0] for el in res if el[1] == c]\n",
    "                #print(nomi)\n",
    "                result_set = computeMedoidsAsName(result_set, iban, nomi, d)\n",
    "                \n",
    "            \n",
    "accuracy = 0 \n",
    "for el in result_set:\n",
    "    if result_set[el][\"Real_IsShared\"] == result_set[el][\"IsShared\"]:\n",
    "        accuracy += 1\n",
    "\n",
    "print(accuracy / len(result_set) * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
