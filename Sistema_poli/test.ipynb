{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['BIC', 'AccountNumber', 'CTRYbnk', 'Name', 'IsShared', 'Holder'], dtype='object')\n",
      "657\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\".\\dataset_100_IBAN_prova.csv\",index_col=0)\n",
    "dataset = dataset.drop(\"Address\",axis=1)\n",
    "\n",
    "print(dataset.columns)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "abbreviation_variations = [\n",
    "    [\"Group\", \"Grp\", \"Gr\", \"Gp\"],\n",
    "    [\"Corporation\", \"Corp\", \"Corp\", \"Corp\", \"Cpn\"],\n",
    "    [\"Holdings\", \"Hldgs\", \"Hdg\", \"Hdgs\"],\n",
    "    [\"Enterprises\", \"Ent\", \"Ents\"],\n",
    "    [\"International\",\"Intl\", \"Int\"],\n",
    "    [\"Global\", \"Glob\", \"Glb\"],\n",
    "    [\"Solutions\", \"Solns\", \"Sols\"],\n",
    "    [\"Services\", \"Svcs\", \"Sv\"],\n",
    "    [\"Technologies\", \"Tech\", \"Techs\"],\n",
    "    [\"Industries\", \"Inds\", \"Ind\"],\n",
    "    [\"Partners\", \"Ptnrs\", \"Pts\"],\n",
    "    [\"Systems\",\"Sys\", \"Syss\"],\n",
    "    [\"Worldwide\", \"WW\"],\n",
    "    [\"Ventures\", \"Vntrs\", \"Vnts\"],\n",
    "    [\"Brothers\", \"Bros\",  \"Br\"],\n",
    "    [\"Sons\", \"Sns\", \"S\"],\n",
    "    [\"Company\", \"Co\", \"Cpny\", \"Comp\"],\n",
    "    [\"Associates\", \"Assocs\", \"Ass\"],\n",
    "\n",
    "    #\"Incorporated\": \n",
    "    [\"Inc\", \"Incorporated\"],\n",
    "    \n",
    "    #\"Limited\": \n",
    "    [\"LLC\", \"Ltd\", \"Limited\", \"Ltée\", \"LTD\", \"Ltd\", \"Ltda\", \"LTT\"],\n",
    "    \n",
    "    #\"Private Limited\": \n",
    "    [\"Pvt\",\"Public Limited Company\",  \"plc\", \"PLCC\",  \"Public\"],\n",
    "    \n",
    "    #\"Società Italiane\n",
    "    [\"SpA\", \"Società per Azioni\", \"Srl\", \"SAPA\", \"SAS\", \"SC\", \"SA\", \"SCARL\", \"SDF\", \"SU\", \"SNC\", \"Scoop\"],\n",
    "]\n",
    "\n",
    "# nltk.download('punkt')\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def remove_company_abbreviations(text):\n",
    "    init = text.split()\n",
    "    for lista in abbreviation_variations:\n",
    "        for el in lista:\n",
    "            if el.lower() in init:\n",
    "                init = [elem for elem in init if el.lower() != elem] \n",
    "\n",
    "    return \" \".join(init)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    \"\"\" \"\"\"\n",
    "    for punct in string.punctuation:\n",
    "        text = text.replace(punct,\"\")\n",
    "    return text\n",
    "    # return \"\".join(tokenizer.tokenize(string))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\" \"\"\"\n",
    "    removed = text.lower()\n",
    "    removed = remove_punctuation(removed)\n",
    "    removed = remove_company_abbreviations(removed)\n",
    "    # print(\"PRIMA:\\t\" + text + \"\\t\\t\\t -> \" + removed.upper().strip())\n",
    "    return removed.upper().strip()\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(dataset)):    \n",
    "    if isinstance(dataset.loc[i, \"Name\"],str):\n",
    "        dataset.loc[i, \"Name\"] = preprocess_text(dataset.loc[i, \"Name\"])\n",
    "    \n",
    "dataset = dataset.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jaro\n",
    "import numpy as np\n",
    "from Levenshtein import ratio\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "\n",
    "def computeAvgDistanceInNames(group, iban, d):\n",
    "    \"\"\" \"\"\"\n",
    "    couples = list(combinations(group[\"Name\"], 2))\n",
    "    distances = []\n",
    "    \n",
    "    if d == \"edit\":\n",
    "        for couple in couples:distances.append(ratio(couple[0], couple[1]))\n",
    "    elif d == \"jaro\":\n",
    "        for couple in couples:distances.append(jaro.jaro_winkler_metric(couple[0], couple[1]))\n",
    "    elif d == \"hamming\":\n",
    "        for couple in couples:distances.append(distance.hamming(list(couple[0]), list(couple[1])))\n",
    "    else:\n",
    "        raise Exception(\"Distance not supported\")\n",
    "    \n",
    "    return sum(distances) / len(distances)\n",
    "\n",
    "\n",
    "def computeMedoidsAsName(iban, names, d, clusters=None):\n",
    "    \"\"\" \"\"\"\n",
    "    if len(names) == 1:\n",
    "        return names[0]\n",
    "    \n",
    "    distances = []\n",
    "    best = np.inf\n",
    "    best_name = \"\"\n",
    "    for name1 in names:\n",
    "        for name2 in [el for el in names if el != name1]:\n",
    "            if d == \"edit\":\n",
    "                distances.append(ratio(name1, name2))\n",
    "            elif d == \"jaro\":\n",
    "                distances.append(jaro.jaro_winkler_metric(name1, name2))\n",
    "            elif d == \"hamming\":\n",
    "                distances.append(distance.hamming(list(name1), list(name2)))\n",
    "            else:\n",
    "                raise Exception(\"Distance not supported\")\n",
    "        \n",
    "        actual = sum(distances) / (len(names) - 1)\n",
    "        if best > actual:\n",
    "            best = actual\n",
    "            best_name = name1\n",
    "\n",
    "    return best_name\n",
    "\n",
    "\n",
    "def AgglomerativeC(iban, names, d, cluster_threshold):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    # Compute the pairwise distance matrix\n",
    "    n = len(names)\n",
    "    distance_matrix = np.zeros((n, n))\n",
    "\n",
    "    if d == \"edit\":\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                dist = ratio(names[i], names[j])\n",
    "                distance_matrix[i, j] = 1 -dist\n",
    "                distance_matrix[j, i] = 1 -dist\n",
    "\n",
    "    elif d == \"jaro\":\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                dist = jaro.jaro_winkler_metric(names[i], names[j])\n",
    "                distance_matrix[i, j] = dist\n",
    "                distance_matrix[j, i] = dist        \n",
    "\n",
    "    # Perform agglomerative clustering\n",
    "    clustering = AgglomerativeClustering( n_clusters=None, metric='precomputed', linkage='average', distance_threshold=cluster_threshold)\n",
    "    clusters = clustering.fit_predict(distance_matrix)\n",
    "    # Print the resulting clusters\n",
    "    #for idx, cluster in enumerate(clusters):\n",
    "    #    print(f\"String: {names[idx]}, Cluster: {cluster}\")    \n",
    "    \n",
    "    return clusters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 114.89it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "d = \"jaro\"\n",
    "threshold = 0.37\n",
    "cluster_threshold = 0.4\n",
    "\n",
    "dataset_result = dataset.copy(deep=True)\n",
    "dataset_result[\"is_shared_polito\"] = None\n",
    "dataset_result[\"party_name_polito\"] = None\n",
    "dataset_result[\"cluster_polito\"] = None\n",
    "\n",
    "groupped = dataset.groupby(\"AccountNumber\")\n",
    "for iban, group in tqdm(groupped):\n",
    "    if len(group) == 1:\n",
    "        dataset_result.loc[dataset_result[\"AccountNumber\"] == iban, \"is_shared_polito\"] = 0\n",
    "        dataset_result.loc[dataset_result[\"AccountNumber\"] == iban, \"party_name_polito\"] = group[\"Name\"].tolist()[0]\n",
    "        dataset_result.loc[dataset_result[\"AccountNumber\"] == iban, \"cluster_polito\"] = 0\n",
    "    else:\n",
    "        avg_distance_acc = computeAvgDistanceInNames(group, iban, d)       \n",
    "        if avg_distance_acc <= threshold:\n",
    "            name = computeMedoidsAsName(iban, group['Name'].tolist(), d)\n",
    "\n",
    "            dataset_result.loc[dataset_result[\"AccountNumber\"] == iban, \"is_shared_polito\"] = 0\n",
    "            dataset_result.loc[dataset_result[\"AccountNumber\"] == iban, \"party_name_polito\"] = name\n",
    "            dataset_result.loc[dataset_result[\"AccountNumber\"] == iban, \"cluster_polito\"] = 0\n",
    "        else:\n",
    "            name_list = group[\"Name\"].tolist()\n",
    "            clusters = AgglomerativeC(iban, name_list, d, cluster_threshold)\n",
    "            res = list(enumerate(clusters))\n",
    "            res = [(name_list[el[0]], el[1]) for el in res]\n",
    "            clusters = list(set(clusters))\n",
    "\n",
    "            dataset_result.loc[dataset_result[\"AccountNumber\"] == iban, \"is_shared_polito\"] = 1\n",
    "            for c in clusters:\n",
    "                nomi = [el[0] for el in res if el[1] == c]\n",
    "                best_name = computeMedoidsAsName(iban, nomi, d)\n",
    "                dataset_result.loc[(dataset_result[\"AccountNumber\"] == iban) & (dataset_result[\"Name\"].isin(nomi)), \"party_name_polito\"] = best_name\n",
    "                dataset_result.loc[(dataset_result[\"AccountNumber\"] == iban) & (dataset_result[\"Name\"].isin(nomi)), \"cluster_polito\"] = c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.69\n",
      "precision\t0.59\n",
      "recall\t\t0.95\n",
      "f-score\t\t0.73\n",
      "cluster\t\t0.9670781893004116\n"
     ]
    }
   ],
   "source": [
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "holder_right = 0\n",
    "cluster_rigth = 0\n",
    "tot_cluster = 0\n",
    "\n",
    "for account_number, group in dataset_result.groupby([\"AccountNumber\"]):\n",
    "    is_shared = group.iloc[0][\"IsShared\"]\n",
    "    polito_result = group.iloc[0][\"is_shared_polito\"]\n",
    "\n",
    "    if polito_result and is_shared:\n",
    "        tp += 1\n",
    "    elif not polito_result and not is_shared:\n",
    "        tn += 1\n",
    "    elif polito_result and not is_shared:\n",
    "        fp += 1\n",
    "    elif not polito_result and is_shared:\n",
    "        fn += 1\n",
    "\n",
    "    names = group[\"Name\"].tolist()\n",
    "    holder = group[\"Holder\"].tolist()\n",
    "    party = group[\"party_name_polito\"].tolist()\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        p = party[i]\n",
    "        index_n = names.index(p)\n",
    "        real_name = holder[index_n]\n",
    "        if holder[i] == real_name:\n",
    "            holder_right +=1\n",
    "\n",
    "    num_cluster = max(set(group[\"cluster_polito\"])) + 1\n",
    "    num_real_cluster = len(set(group[\"Holder\"]))\n",
    "    tot_cluster += num_real_cluster\n",
    "    if num_cluster == num_real_cluster:\n",
    "        cluster_rigth +=1\n",
    "\n",
    "cluster_accuracy = holder_right / len(dataset_result)   \n",
    "accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "precision =(tp)/(tp+fp)\n",
    "recall = (tp)/(tp+fn)\n",
    "fscore = (2*precision*recall)/(precision+recall)\n",
    "\n",
    "print(\"accuracy\\t\" + str(round(accuracy, 2)))\n",
    "print(\"precision\\t\" + str(round(precision, 2)))\n",
    "print(\"recall\\t\\t\" + str(round(recall, 2)))\n",
    "print(\"f-score\\t\\t\"+ str(round(fscore, 2)))\n",
    "print(\"cluster\\t\\t\" + str(cluster_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
